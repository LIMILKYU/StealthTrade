# íŠ¸ë ˆì´ë”© ì„±ê³¼ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ AI ìµœì í™” ì‹œìŠ¤í…œì— ë°˜ì˜
# AIê°€ ìë™ìœ¼ë¡œ ì „ëµì„ ìˆ˜ì •í•˜ê³  ì§€ì†ì ìœ¼ë¡œ í•™ìŠµ

import logging
from ai_optimization.ai_model import LSTMAIModel
from ai_optimization.reinforcement_learning import DQNAgent
from ai_optimization.data_feed import DataFeed
from ai_optimization.strategy_feedback import StrategyFeedback

class AIRealTimeOptimizer:
    def __init__(self, api_url: str, trade_log_file: str):
        self.data_feed = DataFeed(api_url)
        self.lstm_model = LSTMAIModel(input_shape=(50, 5))
        self.rl_agent = DQNAgent(state_size=5, action_size=2)
        self.strategy_feedback = StrategyFeedback(trade_log_file)
        logging.basicConfig(level=logging.INFO)

    def update_strategy(self):
        """ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ëµ ìµœì í™” ë° ì„±ê³¼ í”¼ë“œë°± """
        self.strategy_feedback.update_strategy()  # ì „ëµ ì—…ë°ì´íŠ¸ ë°˜ì˜
        df = self.data_feed.get_market_data()

        if df is not None:
            prediction = self.lstm_model.predict(df.values.reshape(1, 50, 5))
            signal = "BUY" if prediction[0] == 1 else "SELL"
            action = self.rl_agent.act(df.iloc[-1].values)
            optimized_signal = "BUY" if action == 1 else "SELL"

            logging.info(f"ğŸ“ˆ AI Signal: {signal}, RL Optimized Signal: {optimized_signal}")

            return optimized_signal

        return None

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    optimizer = AIRealTimeOptimizer("https://api.binance.com/api/v3/ticker/24hr", "data/trade_log.csv")
    print(optimizer.update_strategy())

