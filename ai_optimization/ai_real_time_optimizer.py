import logging
import pandas as pd
import numpy as np
import requests
import os
from dotenv import load_dotenv
from ai_optimization.ai_model import LSTMAIModel
from ai_optimization.reinforcement_learning import DQNAgent
from ai_optimization.data_feed import DataFeed
from ai_optimization.strategy_feedback import StrategyFeedback
from backend.t_rpc_client import tRPCClient
from notification.telegram_notifier import TelegramNotifier

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class AIRealTimeOptimizer:
    def __init__(self):
        """ AI ê¸°ë°˜ ì‹¤ì‹œê°„ ì „ëµ ìµœì í™” ì‹œìŠ¤í…œ """
        self.api_url = os.getenv("TRPC_API_URL")  # tRPC API URL
        self.data_feed = DataFeed(self.api_url)
        self.lstm_model = LSTMAIModel(input_shape=(50, 7))  # ë°ì´í„° í¬ì¸íŠ¸ ì¶”ê°€
        self.rl_agent = DQNAgent(state_size=7, action_size=2)
        self.strategy_feedback = StrategyFeedback("logs/trade_history.log")
        self.telegram_notifier = TelegramNotifier(
            os.getenv("TELEGRAM_BOT_TOKEN"), os.getenv("TELEGRAM_CHAT_ID")
        )
        self.trpc_client = tRPCClient(self.api_url)

        logging.basicConfig(level=logging.INFO)

    def update_strategy(self):
        """ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ì „ëµ ìµœì í™” """
        try:
            df = self.data_feed.get_market_data()
            if df is None or df.empty:
                logging.warning("âŒ ì‹œì¥ ë°ì´í„° ì—†ìŒ! ì „ëµ ì—…ë°ì´íŠ¸ ë¶ˆê°€")
                return

            # ë°ì´í„° ê°€ê³µ (ì‹œì¥ ë³€ë™ì„±, ì²´ê²° ê°•ë„, ë§¤ìˆ˜/ë§¤ë„ ë¶ˆê· í˜• ì¶”ê°€)
            df["volatility"] = df["price"].pct_change().rolling(10).std()
            df["bid_ask_imbalance"] = df["bid_volume"] - df["ask_volume"]
            df["trade_volume_change"] = df["trade_volume"].pct_change()

            # LSTM ëª¨ë¸ ì˜ˆì¸¡
            prediction = self.lstm_model.predict(df.iloc[-50:].values.reshape(1, 50, 7))
            signal = "BUY" if prediction[0] > 0.5 else "SELL"

            # ê°•í™” í•™ìŠµ ê¸°ë°˜ AI ìµœì í™” ì ìš©
            state = df.iloc[-1].values
            action = self.rl_agent.act(state)

            # ì „ëµ ì—…ë°ì´íŠ¸ ë°˜ì˜
            self.strategy_feedback.update_strategy(action, signal)

            # tRPC APIë¥¼ í†µí•´ í”„ë¡ íŠ¸ì—”ë“œ ì—…ë°ì´íŠ¸
            self.trpc_client.update_trade_data({
                "ai_signal": signal,
                "rl_action": action,
                "volatility": df["volatility"].iloc[-1],
                "bid_ask_imbalance": df["bid_ask_imbalance"].iloc[-1],
            })

            # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡
            self.telegram_notifier.send_message(
                f"ğŸ“Š **AI ì „ëµ ìµœì í™” ì—…ë°ì´íŠ¸**\n"
                f"âœ… ì˜ˆì¸¡ ì‹ í˜¸: {signal}\n"
                f"ğŸ”¹ ê°•í™” í•™ìŠµ ì•¡ì…˜: {action}\n"
                f"ğŸ“ˆ ì‹œì¥ ë³€ë™ì„±: {df['volatility'].iloc[-1]:.5f}\n"
                f"ğŸ“Š ë§¤ìˆ˜/ë§¤ë„ ë¶ˆê· í˜•: {df['bid_ask_imbalance'].iloc[-1]}"
            )

        except requests.exceptions.RequestException as e:
            logging.error(f"ğŸš¨ API ì˜¤ë¥˜ ë°œìƒ: {e}")
        except Exception as e:
            logging.error(f"âš ï¸ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    optimizer = AIRealTimeOptimizer()
    optimizer.update_strategy()
