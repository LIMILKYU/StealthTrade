# ğŸ“Œ ì‹œê³„ì—´ ë¶„ì„ ì£¼ìš” ëª©í‘œ
# âœ… ê³ ì „ì  ì‹œê³„ì—´ ëª¨ë¸ ì ìš© (ARIMA, GARCH ë“±)
# âœ… ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ (LSTM, Transformer í™œìš© ê°€ëŠ¥)
# âœ… ìê¸°ìƒê´€ì„± ë¶„ì„ (ACF, PACF) â†’ ìµœì  ëª¨ë¸ ì„ íƒ
# âœ… íŒŒìƒ ì§€í‘œ (íŒŒì›Œ ìŠ¤í™íŠ¸ëŸ¼, í“¨ë¦¬ì— ë³€í™˜) ë¶„ì„ â†’ íŒ¨í„´ ê°ì§€
# âœ… ë©€í‹°íƒ€ì„í”„ë ˆì„ ë°ì´í„° í™œìš© (í‹± ë°ì´í„° ~ ì¼ë´‰ê¹Œì§€)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.tsa.arima.model import ARIMA
from arch import arch_model
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import MinMaxScaler
from ohlcv_collector import OHLCVCollector  # OHLCV ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ

class TimeSeriesAnalysis:
    def __init__(self, asset="BTCUSDT", interval="1h", use_lstm=False):
        """
        ì‹œê³„ì—´ ë¶„ì„ í´ë˜ìŠ¤
        :param asset: ë¶„ì„í•  ìì‚° (ì˜ˆ: BTCUSDT)
        :param interval: ë°ì´í„° ê°„ê²© (ì˜ˆ: "1h", "15m")
        :param use_lstm: LSTM ëª¨ë¸ì„ ì‚¬ìš©í• ì§€ ì—¬ë¶€
        """
        self.asset = asset
        self.interval = interval
        self.use_lstm = use_lstm
        self.price_collector = OHLCVCollector()
        self.scaler = MinMaxScaler(feature_range=(-1, 1))

    def fetch_data(self, lookback=500):
        """
        ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
        """
        df = self.price_collector.get_ohlcv(self.asset, self.interval, lookback)
        df['returns'] = df['close'].pct_change()
        return df.dropna()

    def stationarity_test(self, df):
        """
        ADF ê²€ì •ì„ í†µí•œ ì •ìƒì„±(Stationarity) í…ŒìŠ¤íŠ¸
        """
        result = adfuller(df["close"])
        return {"ADF Statistic": result[0], "p-value": result[1]}

    def plot_acf_pacf(self, df):
        """
        ìê¸°ìƒê´€í•¨ìˆ˜(ACF) ë° ë¶€ë¶„ìê¸°ìƒê´€(PACF) ë¶„ì„
        """
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        sns.lineplot(x=range(len(df)), y=acf(df["returns"], nlags=30), ax=axes[0])
        sns.lineplot(x=range(len(df)), y=pacf(df["returns"], nlags=30), ax=axes[1])
        axes[0].set_title("ìê¸°ìƒê´€í•¨ìˆ˜ (ACF)")
        axes[1].set_title("ë¶€ë¶„ìê¸°ìƒê´€í•¨ìˆ˜ (PACF)")
        plt.show()

    def arima_model(self, df):
        """
        ARIMA ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹œê³„ì—´ ì˜ˆì¸¡
        """
        model = ARIMA(df["close"], order=(5,1,0))
        result = model.fit()
        return result.summary()

    def garch_model(self, df):
        """
        GARCH ëª¨ë¸ì„ ì‚¬ìš©í•œ ë³€ë™ì„± ì˜ˆì¸¡
        """
        model = arch_model(df["returns"].dropna() * 100, vol="Garch", p=1, q=1)
        result = model.fit(disp="off")
        return result.summary()

    def preprocess_lstm(self, df, lookback=50):
        """
        LSTMì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬
        """
        data = self.scaler.fit_transform(df[['close']].values)
        x_train, y_train = [], []
        for i in range(lookback, len(data)):
            x_train.append(data[i-lookback:i, 0])
            y_train.append(data[i, 0])
        return torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)

    def train_lstm(self, df, lookback=50, epochs=20, batch_size=32):
        """
        LSTMì„ í™œìš©í•œ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨
        """
        class LSTMModel(nn.Module):
            def __init__(self):
                super(LSTMModel, self).__init__()
                self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=2, batch_first=True)
                self.fc = nn.Linear(50, 1)

            def forward(self, x):
                h0 = torch.zeros(2, x.size(0), 50)
                c0 = torch.zeros(2, x.size(0), 50)
                out, _ = self.lstm(x.unsqueeze(2), (h0, c0))
                return self.fc(out[:, -1, :])

        x_train, y_train = self.preprocess_lstm(df, lookback)
        model = LSTMModel()
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)

        for epoch in range(epochs):
            optimizer.zero_grad()
            outputs = model(x_train)
            loss = criterion(outputs.squeeze(), y_train)
            loss.backward()
            optimizer.step()
            if epoch % 5 == 0:
                print(f"Epoch {epoch}: Loss {loss.item()}")

        return model

    def run_analysis(self):
        """
        ì‹œê³„ì—´ ë¶„ì„ ì‹¤í–‰
        """
        df = self.fetch_data()
        print("ğŸ“Š ë°ì´í„° ì •ìƒì„± ê²€ì • (ADF Test) ê²°ê³¼:")
        print(self.stationarity_test(df))

        print("\nğŸ“Š ARIMA ëª¨ë¸ ê²°ê³¼:")
        print(self.arima_model(df))

        print("\nğŸ“Š GARCH ëª¨ë¸ ê²°ê³¼:")
        print(self.garch_model(df))

        if self.use_lstm:
            print("\nğŸ“Š LSTM ëª¨ë¸ í•™ìŠµ ì¤‘...")
            lstm_model = self.train_lstm(df)
            return lstm_model
        else:
            self.plot_acf_pacf(df)
            return None

# ì‹¤í–‰ ì˜ˆì œ
# ts = TimeSeriesAnalysis(use_lstm=True)
# ts.run_analysis()
